{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG TRANSFER LEARNING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARE DATASET \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 image_id  label\n",
      "0  S10/B03/B03_R1/S10_B03_R1_IMAG0958.JPG      5\n",
      "1  S10/B03/B03_R1/S10_B03_R1_IMAG0992.JPG      5\n",
      "2  S10/B03/B03_R1/S10_B03_R1_IMAG1049.JPG      5\n",
      "3  S10/B03/B03_R1/S10_B03_R1_IMAG1115.JPG      5\n",
      "4  S10/B03/B03_R1/S10_B03_R1_IMAG1307.JPG      5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data prepare: 2 classes [5,21] for quick check \n",
    "# VGG data prepare\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_file = '/root/data/S10.json'\n",
    "with open(train_file) as data_file:\n",
    "    train_anns=json.load(data_file)\n",
    "\n",
    "\n",
    "img_5=[]\n",
    "for i in train_anns['annotations']:\n",
    "    if i['category_id'] == 5:\n",
    "        img_5.append(i['image_id']+'.JPG')\n",
    "img_5_1w = random.sample(img_5, 1300)\n",
    "\n",
    "\n",
    "img_21=[]\n",
    "for i in train_anns['annotations']:\n",
    "    if i['category_id'] == 21:\n",
    "        img_21.append(i['image_id']+'.JPG')\n",
    "img_21_1w = random.sample(img_21,1300)\n",
    "\n",
    "img_list = img_5_1w+img_21_1w\n",
    "\n",
    "label_dict = {}\n",
    "for i in train_anns['annotations']:\n",
    "    i_new = i['image_id'] + '.JPG'\n",
    "    if i_new in img_list:\n",
    "        label_dict[i_new]=i['category_id']\n",
    "        \n",
    "df = pd.DataFrame.from_dict(label_dict,orient='index',columns=['label'])\n",
    "df = df.reset_index().rename(columns={'index':'image_id'})\n",
    "print(df.head())\n",
    "\n",
    "df['label'].value_counts().plot.bar()\n",
    "plt.show()\n",
    "\n",
    "df.label.unique()\n",
    "\n",
    "df.loc[df.label == 39, 'label']=21\n",
    "\n",
    "df.label.unique()\n",
    "\n",
    "df['label'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 21])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.label == 5, 'label']=0\n",
    "df.loc[df.label == 21, 'label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S10/B03/B03_R1/S10_B03_R1_IMAG0958.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S10/B03/B03_R1/S10_B03_R1_IMAG0992.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>S10/B03/B03_R1/S10_B03_R1_IMAG1049.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S10/B03/B03_R1/S10_B03_R1_IMAG1115.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>S10/B03/B03_R1/S10_B03_R1_IMAG1307.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2595</td>\n",
       "      <td>S10/T11/T11_R2/S10_T11_R2_IMAG1007.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2596</td>\n",
       "      <td>S10/T11/T11_R2/S10_T11_R2_IMAG1020.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2597</td>\n",
       "      <td>S10/T11/T11_R2/S10_T11_R2_IMAG1084.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2598</td>\n",
       "      <td>S10/T11/T11_R2/S10_T11_R2_IMAG1098.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2599</td>\n",
       "      <td>S10/T11/T11_R2/S10_T11_R2_IMAG1822.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2600 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image_id  label\n",
       "0     S10/B03/B03_R1/S10_B03_R1_IMAG0958.JPG      0\n",
       "1     S10/B03/B03_R1/S10_B03_R1_IMAG0992.JPG      0\n",
       "2     S10/B03/B03_R1/S10_B03_R1_IMAG1049.JPG      0\n",
       "3     S10/B03/B03_R1/S10_B03_R1_IMAG1115.JPG      0\n",
       "4     S10/B03/B03_R1/S10_B03_R1_IMAG1307.JPG      0\n",
       "...                                      ...    ...\n",
       "2595  S10/T11/T11_R2/S10_T11_R2_IMAG1007.JPG      0\n",
       "2596  S10/T11/T11_R2/S10_T11_R2_IMAG1020.JPG      0\n",
       "2597  S10/T11/T11_R2/S10_T11_R2_IMAG1084.JPG      0\n",
       "2598  S10/T11/T11_R2/S10_T11_R2_IMAG1098.JPG      0\n",
       "2599  S10/T11/T11_R2/S10_T11_R2_IMAG1822.JPG      0\n",
       "\n",
       "[2600 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=523)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S10/O09/O09_R2/S10_O09_R2_IMAG1908.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S10/C08/C08_R1/S10_C08_R1_IMAG0262.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_id  label\n",
       "0  S10/O09/O09_R2/S10_O09_R2_IMAG1908.JPG      0\n",
       "1  S10/C08/C08_R1/S10_C08_R1_IMAG0262.JPG      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the not existed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = df['image_id'].tolist()\n",
    "path = '/root/data/'\n",
    "\n",
    "count = 0\n",
    "nonelist = []\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path)\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist.append(img_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S10/E06/E06_R1/S10_E06_R1_IMAG0874.JPG',\n",
       " 'S10/E06/E06_R1/S10_E06_R1_IMAG0875.JPG',\n",
       " 'S10/E06/E06_R1/S10_E06_R1_IMAG0876.JPG',\n",
       " 'S10/I06/I06_R1/S10_I06_R1_IMAG1192.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0489.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0490.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0491.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0492.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0493.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0494.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0495.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0496.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0497.JPG',\n",
       " 'S10/M08/M08_R1/S10_M08_R1_IMAG0261.JPG',\n",
       " 'S10/M08/M08_R1/S10_M08_R1_IMAG0262.JPG',\n",
       " 'S10/M08/M08_R1/S10_M08_R1_IMAG0263.JPG',\n",
       " 'S10/M08/M08_R1/S10_M08_R1_IMAG0268.JPG',\n",
       " 'S10/M08/M08_R1/S10_M08_R1_IMAG0269.JPG']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonelist1 = []\n",
    "for i in nonelist:\n",
    "    j = i[:]\n",
    "    nonelist1.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S10_E06_R1_IMAG0874.JPG',\n",
       " 'S10_E06_R1_IMAG0875.JPG',\n",
       " 'S10_E06_R1_IMAG0876.JPG',\n",
       " 'S10_I06_R1_IMAG1192.JPG',\n",
       " 'S10_K09_R1_IMAG0489.JPG',\n",
       " 'S10_K09_R1_IMAG0490.JPG',\n",
       " 'S10_K09_R1_IMAG0491.JPG',\n",
       " 'S10_K09_R1_IMAG0492.JPG',\n",
       " 'S10_K09_R1_IMAG0493.JPG',\n",
       " 'S10_K09_R1_IMAG0494.JPG',\n",
       " 'S10_K09_R1_IMAG0495.JPG',\n",
       " 'S10_K09_R1_IMAG0496.JPG',\n",
       " 'S10_K09_R1_IMAG0497.JPG',\n",
       " 'S10_M08_R1_IMAG0261.JPG',\n",
       " 'S10_M08_R1_IMAG0262.JPG',\n",
       " 'S10_M08_R1_IMAG0263.JPG',\n",
       " 'S10_M08_R1_IMAG0268.JPG',\n",
       " 'S10_M08_R1_IMAG0269.JPG']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonelist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[~df.image_id.isin(nonelist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2582"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df1, test_size=0.20, random_state=523)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2065"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = train_df['image_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.empty((len(imglist),227,227,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.empty((len(imglist),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2065, 227, 227, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2065, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/root/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S10/P13/P13_R3/S10_P13_R3_IMAG0767.JPG',\n",
       " 'S10/M09/M09_R3/S10_M09_R3_IMAG0588.JPG']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imglist[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "nonelist=[]\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(227,227))\n",
    "#         img = image.img_to_array(img)/255.0\n",
    "        X_train[count]=img\n",
    "#         Y_train[count]=np.array((1,0))\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.34117648, 0.44705883, 0.62352943],\n",
       "         [0.35294119, 0.48627451, 0.63529414],\n",
       "         [0.3764706 , 0.47058824, 0.65098041],\n",
       "         ...,\n",
       "         [0.30980393, 0.45490196, 0.65882355],\n",
       "         [0.30980393, 0.41176471, 0.64313728],\n",
       "         [0.34117648, 0.4509804 , 0.63921571]],\n",
       "\n",
       "        [[0.08627451, 0.06666667, 0.09019608],\n",
       "         [0.35294119, 0.4627451 , 0.65098041],\n",
       "         [0.36862746, 0.45490196, 0.63921571],\n",
       "         ...,\n",
       "         [0.35294119, 0.44313726, 0.64705884],\n",
       "         [0.32156864, 0.44313726, 0.66666669],\n",
       "         [0.34509805, 0.45490196, 0.64313728]],\n",
       "\n",
       "        [[0.31764707, 0.3137255 , 0.38431373],\n",
       "         [0.34509805, 0.47843137, 0.62352943],\n",
       "         [0.39607844, 0.46666667, 0.65490198],\n",
       "         ...,\n",
       "         [0.32549021, 0.44313726, 0.64705884],\n",
       "         [0.34117648, 0.44313726, 0.64313728],\n",
       "         [0.34117648, 0.44705883, 0.65490198]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.86274511, 0.86274511, 0.86274511],\n",
       "         [0.86274511, 0.86274511, 0.86274511],\n",
       "         [0.89019608, 0.89019608, 0.89019608],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.85882354, 0.85882354, 0.85882354],\n",
       "         [0.85882354, 0.86666667, 0.84705883]],\n",
       "\n",
       "        [[0.86274511, 0.86274511, 0.86274511],\n",
       "         [0.86666667, 0.86666667, 0.86666667],\n",
       "         [0.84313726, 0.84313726, 0.84313726],\n",
       "         ...,\n",
       "         [0.03529412, 0.03529412, 0.03529412],\n",
       "         [0.89803922, 0.89803922, 0.89803922],\n",
       "         [0.86666667, 0.86274511, 0.85490197]],\n",
       "\n",
       "        [[0.85490197, 0.88627452, 0.82745099],\n",
       "         [0.88627452, 0.86274511, 0.87058824],\n",
       "         [0.86666667, 0.8509804 , 0.85490197],\n",
       "         ...,\n",
       "         [0.83529413, 0.86666667, 0.87843138],\n",
       "         [0.86274511, 0.86666667, 0.88627452],\n",
       "         [0.86666667, 0.85490197, 0.88235295]]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_df['label']\n",
    "Y_train = [i for i in label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2065,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=d.reshape(2065,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2065, 1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S10/P13/P13_R3/S10_P13_R3_IMAG0861.JPG</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S10/M09/M09_R3/S10_M09_R3_IMAG0570.JPG</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_id  label\n",
       "0  S10/P13/P13_R3/S10_P13_R3_IMAG0861.JPG      5\n",
       "1  S10/M09/M09_R3/S10_M09_R3_IMAG0570.JPG     21"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5],\n",
       "       [21]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 227, 227, 3)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imglist = validate_df['image_id'].tolist()\n",
    "X_validate = np.empty((len(imglist),227,227,3))\n",
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "nonelist_validate=[]\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(227,227))\n",
    "        img = image.img_to_array(img)/255.0\n",
    "        X_validate[count]=img\n",
    "#         Y_train[count]=np.array((1,0))\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist_validate.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 227, 227, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = validate_df['label']\n",
    "Y_validate = [i for i in label]\n",
    "Y_validate = np.array(Y_validate)\n",
    "Y_validate = Y_validate.reshape(len(Y_validate),1)\n",
    "Y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S10/P13/P13_R3/S10_P13_R3_IMAG0864.JPG</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S10/M09/M09_R3/S10_M09_R3_IMAG0622.JPG</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_id  label\n",
       "0  S10/P13/P13_R3/S10_P13_R3_IMAG0864.JPG      5\n",
       "1  S10/M09/M09_R3/S10_M09_R3_IMAG0622.JPG     21"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5],\n",
       "       [21]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_validate[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data \n",
    "\n",
    "- X_train\n",
    "- Y_train\n",
    "- X_validate\n",
    "- Y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classes_num = 2\n",
    "batch_size = 32\n",
    "epochs_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # ????\n",
    "    (x_train, y_train), (x_test, y_test) = (X_train,Y_train), (X_validate, Y_validate)\n",
    "\n",
    "    # ???????\n",
    "#     y_train = keras.utils.to_categorical(y_train, classes_num)\n",
    "#     y_test = keras.utils.to_categorical(y_test, classes_num)\n",
    "#     # ??????\n",
    "#     x_train = x_train.astype('float32')\n",
    "#     x_test = x_test.astype('float32')\n",
    "\n",
    "    datagan = ImageDataGenerator(rescale=1.)\n",
    "\n",
    "    # \n",
    "    conv_base = VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    # \n",
    "    sample_count = len(y_train)\n",
    "    train_features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    train_labels = np.zeros(shape=(sample_count, classes_num))\n",
    "    train_generator = datagan.flow(x_train, y_train, batch_size=batch_size)\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in train_generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        train_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    # train_features = np.reshape(train_features, (sample_count, 4*4*512))\n",
    "    \n",
    "    # ??????????????????\n",
    "    sample_count = len(y_test)\n",
    "    test_generator = datagan.flow(x_test, y_test, batch_size=batch_size)\n",
    "    test_features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    test_labels = np.zeros(shape=(sample_count, classes_num))\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in test_generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        test_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        test_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    # test_features = np.reshape(test_features, (sample_count, 4*4*512))\n",
    "    # ??????????????????\n",
    "    sample_count = len(y_test)\n",
    "    test_generator = datagan.flow(x_test, y_test, batch_size=batch_size)\n",
    "    test_features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    test_labels = np.zeros(shape=(sample_count, classes_num))\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in test_generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        test_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        test_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    # test_features = np.reshape(test_features, (sample_count, 4*4*512))\n",
    "    \n",
    "    \n",
    "    model = quality_classify_model()\n",
    "\n",
    "    # hist = model.fit_generator(train_datagan.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch = 8000, epochs = epochs_num, validation_data=(x_test,y_test), shuffle=True)\n",
    "    hist = model.fit(train_features, train_labels, batch_size=batch_size, epochs=epochs_num, validation_data=(test_features, test_labels))\n",
    "\n",
    "    model.save('./extract_features/cifar10_model.hdf5') \n",
    "    model.save_weights('./extract_features/cifar10_model_weight.hdf5')\n",
    "\n",
    "    hist_dict = hist.history\n",
    "    print(\"train acc:\")\n",
    "    print(hist_dict['acc'])\n",
    "    print(\"validation acc:\")\n",
    "    print(hist_dict['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_classify_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(4,4,512)))# 4*4*512\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes_num, activation='softmax'))  # ???\n",
    "\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (32,7,7,512) into shape (32,4,4,512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-130-9457e89c4769>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfeatures_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtrain_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (32,7,7,512) into shape (32,4,4,512)"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classes_num = 2\n",
    "batch_size = 32\n",
    "epochs_num = 100\n",
    "\n",
    "def quality_classify_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(4,4,512)))# 4*4*512\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes_num, activation='softmax'))  # ???\n",
    "\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train():\n",
    "    # ????\n",
    "    x_train, y_train  = X_train, Y_train\n",
    "    x_test, y_test = X_validate, Y_validate\n",
    "\n",
    "    \n",
    "    # ???????\n",
    "    y_train = keras.utils.to_categorical(y_train, classes_num)\n",
    "    y_test = keras.utils.to_categorical(y_test, classes_num)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    datagan = ImageDataGenerator(rescale=1.)\n",
    "\n",
    "    # ??????????\n",
    "    conv_base = VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    # ??????????????????\n",
    "    sample_count = len(y_train)\n",
    "    train_features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    train_labels = np.zeros(shape=(sample_count, classes_num))\n",
    "    train_generator = datagan.flow(x_train, y_train, batch_size=batch_size)\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in train_generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        train_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    # train_features = np.reshape(train_features, (sample_count, 4*4*512))\n",
    "\n",
    "    # ??????????????????\n",
    "    sample_count = len(y_test)\n",
    "    test_generator = datagan.flow(x_test, y_test, batch_size=batch_size)\n",
    "    test_features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    test_labels = np.zeros(shape=(sample_count, classes_num))\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in test_generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        test_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        test_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    # test_features = np.reshape(test_features, (sample_count, 4*4*512))\n",
    "\n",
    "    model = quality_classify_model()\n",
    "\n",
    "    # hist = model.fit_generator(train_datagan.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch = 8000, epochs = epochs_num, validation_data=(x_test,y_test), shuffle=True)\n",
    "    hist = model.fit(train_features, train_labels, batch_size=batch_size, epochs=epochs_num, validation_data=(test_features, test_labels))\n",
    "\n",
    "    model.save('./extract_features/cifar10_model.hdf5') \n",
    "    model.save_weights('./extract_features/cifar10_model_weight.hdf5')\n",
    "\n",
    "    hist_dict = hist.history\n",
    "    print(\"train acc:\")\n",
    "    print(hist_dict['acc'])\n",
    "    print(\"validation acc:\")\n",
    "    print(hist_dict['val_acc'])\n",
    "\n",
    "    train_acc = hist.history['acc']\n",
    "    val_acc = hist.history['val_acc']\n",
    "    train_loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "\n",
    "    # ??\n",
    "    epochs = range(1, len(train_acc)+1)\n",
    "    plt.plot(epochs, train_acc, 'bo', label = 'Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label = 'Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"accuracy.png\")\n",
    "    plt.figure() # ?????\n",
    "    plt.plot(epochs, train_loss, 'bo', label = 'Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"loss.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train  = X_train, Y_train\n",
    "x_test, y_test = X_validate, Y_validate    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-d0f6b49776b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# y_test = keras.utils.to_categorical(y_test, classes_num)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mcategorical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 22)\n",
    "# y_test = keras.utils.to_categorical(y_test, classes_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5],\n",
       "       [21],\n",
       "       [ 5],\n",
       "       ...,\n",
       "       [21],\n",
       "       [21],\n",
       "       [ 5]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
