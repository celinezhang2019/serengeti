{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 image_id  label\n",
      "0  S10/B03/B03_R1/S10_B03_R1_IMAG0979.JPG      5\n",
      "1  S10/B03/B03_R1/S10_B03_R1_IMAG1043.JPG      5\n",
      "2  S10/B03/B03_R1/S10_B03_R1_IMAG1111.JPG      5\n",
      "3  S10/B03/B03_R1/S10_B03_R1_IMAG1115.JPG      5\n",
      "4  S10/B03/B03_R2/S10_B03_R2_IMAG0004.JPG     21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data prepare: 2 classes [5,21] for quick check \n",
    "# VGG data prepare\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_file = '/root/data/S10.json'\n",
    "with open(train_file) as data_file:\n",
    "    train_anns=json.load(data_file)\n",
    "\n",
    "\n",
    "img_5=[]\n",
    "for i in train_anns['annotations']:\n",
    "    if i['category_id'] == 5:\n",
    "        img_5.append(i['image_id']+'.JPG')\n",
    "img_5_1w = random.sample(img_5, 1300)\n",
    "\n",
    "img_21=[]\n",
    "for i in train_anns['annotations']:\n",
    "    if i['category_id'] == 21:\n",
    "        img_21.append(i['image_id']+'.JPG')\n",
    "img_21_1w = random.sample(img_21,1300)\n",
    "\n",
    "img_list = img_5_1w+img_21_1w\n",
    "\n",
    "label_dict = {}\n",
    "for i in train_anns['annotations']:\n",
    "    i_new = i['image_id'] + '.JPG'\n",
    "    if i_new in img_list:\n",
    "        label_dict[i_new]=i['category_id']\n",
    "        \n",
    "df = pd.DataFrame.from_dict(label_dict,orient='index',columns=['label'])\n",
    "df = df.reset_index().rename(columns={'index':'image_id'})\n",
    "print(df.head())\n",
    "\n",
    "df['label'].value_counts().plot.bar()\n",
    "plt.show()\n",
    "\n",
    "df.label.unique()\n",
    "\n",
    "df.loc[df.label == 39, 'label']=21\n",
    "\n",
    "df.label.unique()\n",
    "\n",
    "df['label'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 21])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.label == 5, 'label']=0\n",
    "df.loc[df.label == 21, 'label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S10/B03/B03_R1/S10_B03_R1_IMAG0979.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S10/B03/B03_R1/S10_B03_R1_IMAG1043.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>S10/B03/B03_R1/S10_B03_R1_IMAG1111.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S10/B03/B03_R1/S10_B03_R1_IMAG1115.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>S10/B03/B03_R2/S10_B03_R2_IMAG0004.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_id  label\n",
       "0  S10/B03/B03_R1/S10_B03_R1_IMAG0979.JPG      0\n",
       "1  S10/B03/B03_R1/S10_B03_R1_IMAG1043.JPG      0\n",
       "2  S10/B03/B03_R1/S10_B03_R1_IMAG1111.JPG      0\n",
       "3  S10/B03/B03_R1/S10_B03_R1_IMAG1115.JPG      0\n",
       "4  S10/B03/B03_R2/S10_B03_R2_IMAG0004.JPG      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imglist = df['image_id'].tolist()\n",
    "path = '/root/data/'\n",
    "\n",
    "count = 0\n",
    "nonelist = []\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path)\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist.append(img_name)\n",
    "\n",
    "len(nonelist)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S10/E06/E06_R1/S10_E06_R1_IMAG0874.JPG',\n",
       " 'S10/E06/E06_R1/S10_E06_R1_IMAG0875.JPG',\n",
       " 'S10/E06/E06_R1/S10_E06_R1_IMAG0876.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0489.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0490.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0491.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0492.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0493.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0494.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0495.JPG',\n",
       " 'S10/K09/K09_R1/S10_K09_R1_IMAG0496.JPG',\n",
       " 'S10/M08/M08_R1/S10_M08_R1_IMAG0261.JPG',\n",
       " 'S10/M08/M08_R1/S10_M08_R1_IMAG0262.JPG',\n",
       " 'S10/M08/M08_R1/S10_M08_R1_IMAG0263.JPG',\n",
       " 'S10/M08/M08_R1/S10_M08_R1_IMAG0267.JPG',\n",
       " 'S10/M08/M08_R1/S10_M08_R1_IMAG0268.JPG',\n",
       " 'S10/M08/M08_R1/S10_M08_R1_IMAG0269.JPG']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2583"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df[~df.image_id.isin(nonelist)]\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df1, test_size=0.20, random_state=523)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2066"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = train_df['image_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.empty((len(imglist),227,227,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.empty((len(imglist),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 227, 227, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/root/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S10/P13/P13_R3/S10_P13_R3_IMAG0422.JPG',\n",
       " 'S10/M09/M09_R3/S10_M09_R3_IMAG0569.JPG']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imglist[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "nonelist=[]\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(227,227))\n",
    "        X_train[count]=img\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[150., 178., 226.],\n",
       "         [143., 180., 225.],\n",
       "         [149., 175., 224.],\n",
       "         ...,\n",
       "         [  1.,   7.,   5.],\n",
       "         [  1.,   7.,   5.],\n",
       "         [  1.,   7.,   5.]],\n",
       "\n",
       "        [[143., 180., 225.],\n",
       "         [144., 183., 226.],\n",
       "         [146., 177., 224.],\n",
       "         ...,\n",
       "         [  1.,   7.,   5.],\n",
       "         [  1.,   7.,   5.],\n",
       "         [  1.,   7.,   5.]],\n",
       "\n",
       "        [[145., 176., 223.],\n",
       "         [145., 178., 223.],\n",
       "         [148., 176., 223.],\n",
       "         ...,\n",
       "         [  1.,   7.,   5.],\n",
       "         [  1.,   7.,   5.],\n",
       "         [  1.,   7.,   7.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[220., 220., 220.],\n",
       "         [220., 220., 220.],\n",
       "         [221., 221., 221.],\n",
       "         ...,\n",
       "         [224., 224., 224.],\n",
       "         [224., 224., 224.],\n",
       "         [221., 221., 219.]],\n",
       "\n",
       "        [[220., 220., 220.],\n",
       "         [220., 220., 220.],\n",
       "         [220., 220., 220.],\n",
       "         ...,\n",
       "         [218., 218., 218.],\n",
       "         [220., 220., 220.],\n",
       "         [218., 218., 218.]],\n",
       "\n",
       "        [[221., 219., 222.],\n",
       "         [221., 221., 223.],\n",
       "         [222., 222., 224.],\n",
       "         ...,\n",
       "         [221., 221., 221.],\n",
       "         [221., 221., 221.],\n",
       "         [214., 214., 214.]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_df['label']\n",
    "Y_train = [i for i in label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=d.reshape(2066,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S10/P13/P13_R3/S10_P13_R3_IMAG0422.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S10/M09/M09_R3/S10_M09_R3_IMAG0569.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_id  label\n",
       "0  S10/P13/P13_R3/S10_P13_R3_IMAG0422.JPG      0\n",
       "1  S10/M09/M09_R3/S10_M09_R3_IMAG0569.JPG      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 227, 227, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imglist = validate_df['image_id'].tolist()\n",
    "X_validate = np.empty((len(imglist),227,227,3))\n",
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "nonelist_validate=[]\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(227,227))\n",
    "        X_validate[count]=img\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist_validate.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 227, 227, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = validate_df['label']\n",
    "Y_validate = [i for i in label]\n",
    "Y_validate = np.array(Y_validate)\n",
    "Y_validate = Y_validate.reshape(len(Y_validate),1)\n",
    "Y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S10/P13/P13_R3/S10_P13_R3_IMAG0521.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S10/M09/M09_R3/S10_M09_R3_IMAG0621.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_id  label\n",
       "0  S10/P13/P13_R3/S10_P13_R3_IMAG0521.JPG      0\n",
       "1  S10/M09/M09_R3/S10_M09_R3_IMAG0621.JPG      1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_validate[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classes_num = 2\n",
    "batch_size = 32\n",
    "epochs_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classes_num = 2\n",
    "batch_size = 32\n",
    "epochs_num = 100\n",
    "\n",
    "def quality_classify_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(4,4,512)))# 4*4*512\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes_num, activation='softmax'))  # ???\n",
    "\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train():\n",
    "    # ????\n",
    "    x_train = X_train\n",
    "    y_train = Y_train\n",
    "    x_test = X_validate\n",
    "    y_test = Y_validate\n",
    "\n",
    "    # ???????\n",
    "    y_train = keras.utils.to_categorical(y_train, classes_num)\n",
    "    y_test = keras.utils.to_categorical(y_test, classes_num)\n",
    "    # ??????\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    datagan = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # ??????????\n",
    "    conv_base = VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    # ??????????????????\n",
    "    sample_count = len(y_train)\n",
    "    train_features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    train_labels = np.zeros(shape=(sample_count, classes_num))\n",
    "    train_generator = datagan.flow(x_train, y_train, batch_size=batch_size)\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in train_generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        train_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    # train_features = np.reshape(train_features, (sample_count, 4*4*512))\n",
    "\n",
    "    # ??????????????????\n",
    "    sample_count = len(y_test)\n",
    "    test_generator = datagan.flow(x_test, y_test, batch_size=batch_size)\n",
    "    test_features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    test_labels = np.zeros(shape=(sample_count, classes_num))\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in test_generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        test_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        test_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    test_features = np.reshape(test_features, (sample_count, 4*4*512))\n",
    "\n",
    "    model = quality_classify_model()\n",
    "\n",
    "    # hist = model.fit_generator(train_datagan.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch = 8000, epochs = epochs_num, validation_data=(x_test,y_test), shuffle=True)\n",
    "    hist = model.fit(train_features, train_labels, batch_size=batch_size, epochs=epochs_num, validation_data=(test_features, test_labels))\n",
    "\n",
    "    model.save('./extract_features/cifar10_model.hdf5') \n",
    "    model.save_weights('./extract_features/cifar10_model_weight.hdf5')\n",
    "\n",
    "    hist_dict = hist.history\n",
    "    print(\"train acc:\")\n",
    "    print(hist_dict['acc'])\n",
    "    print(\"validation acc:\")\n",
    "    print(hist_dict['val_acc'])\n",
    "\n",
    "    train_acc = hist.history['acc']\n",
    "    val_acc = hist.history['val_acc']\n",
    "    train_loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "\n",
    "    # ??\n",
    "    epochs = range(1, len(train_acc)+1)\n",
    "    plt.plot(epochs, train_acc, 'bo', label = 'Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label = 'Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"accuracy.png\")\n",
    "    plt.figure() # ?????\n",
    "    plt.plot(epochs, train_loss, 'bo', label = 'Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (32,7,7,512) into shape (32,4,4,512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-ec810d92c149>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mfeatures_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mtrain_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (32,7,7,512) into shape (32,4,4,512)"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try another vgg transfer learning code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading dataset......\n",
      "[INFO] initializing model......\n",
      "[INFO] compiling model\n",
      "[INFO] training model\n",
      "Train on 2066 samples, validate on 517 samples\n",
      "Epoch 1/40\n",
      "2066/2066 [==============================] - 566s 274ms/step - loss: 1.5770 - acc: 0.7657 - val_loss: 0.3707 - val_acc: 0.8337\n",
      "Epoch 2/40\n",
      "2066/2066 [==============================] - 563s 273ms/step - loss: 0.4361 - acc: 0.8746 - val_loss: 0.1871 - val_acc: 0.9381\n",
      "Epoch 3/40\n",
      "2066/2066 [==============================] - 563s 273ms/step - loss: 0.3267 - acc: 0.8925 - val_loss: 0.2366 - val_acc: 0.9188\n",
      "Epoch 4/40\n",
      "2066/2066 [==============================] - 564s 273ms/step - loss: 0.2542 - acc: 0.9119 - val_loss: 0.2039 - val_acc: 0.9284\n",
      "Epoch 5/40\n",
      "2066/2066 [==============================] - 564s 273ms/step - loss: 0.2049 - acc: 0.9303 - val_loss: 0.1641 - val_acc: 0.9497\n",
      "Epoch 6/40\n",
      "2066/2066 [==============================] - 564s 273ms/step - loss: 0.1896 - acc: 0.9371 - val_loss: 0.1487 - val_acc: 0.9536\n",
      "Epoch 7/40\n",
      "2066/2066 [==============================] - 582s 282ms/step - loss: 0.1351 - acc: 0.9511 - val_loss: 0.1600 - val_acc: 0.9516\n",
      "Epoch 8/40\n",
      "2066/2066 [==============================] - 598s 289ms/step - loss: 0.1039 - acc: 0.9613 - val_loss: 0.0895 - val_acc: 0.9613\n",
      "Epoch 9/40\n",
      "2066/2066 [==============================] - 567s 274ms/step - loss: 0.0957 - acc: 0.9613 - val_loss: 0.0892 - val_acc: 0.9652\n",
      "Epoch 10/40\n",
      "2066/2066 [==============================] - 563s 273ms/step - loss: 0.0566 - acc: 0.9768 - val_loss: 0.0776 - val_acc: 0.9691\n",
      "Epoch 11/40\n",
      "2066/2066 [==============================] - 562s 272ms/step - loss: 0.0703 - acc: 0.9802 - val_loss: 0.0887 - val_acc: 0.9729\n",
      "Epoch 12/40\n",
      "2066/2066 [==============================] - 565s 273ms/step - loss: 0.0627 - acc: 0.9782 - val_loss: 0.0831 - val_acc: 0.9729\n",
      "Epoch 13/40\n",
      "2048/2066 [============================>.] - ETA: 3s - loss: 0.0448 - acc: 0.9844 "
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten,Dense,Dropout,Input\n",
    "from keras.applications import VGG16\n",
    "# from load_data import load_data_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model \n",
    "from keras.utils import np_utils\n",
    "# import\n",
    "print('[INFO] loading dataset......')\n",
    "(x_train,y_train)=(X_train, Y_train)\n",
    "(x_valid,y_valid)=(X_validate, Y_validate)\n",
    "\n",
    "y_train=np_utils.to_categorical(y_train,2)\n",
    "y_valid=np_utils.to_categorical(y_valid,2)\n",
    "print('[INFO] initializing model......')\n",
    "base_model=VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(227,227,3)))\n",
    "\n",
    "#微调\n",
    "head_model=base_model.output\n",
    "head_model=Flatten(name=\"flatten\")(head_model)\n",
    "head_model = Dense(512, activation=\"relu\")(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model=Dense(32,activation='relu')(head_model)\n",
    "head_model = Dense(2, activation=\"softmax\")(head_model)\n",
    "model=Model(base_model.input,head_model)\n",
    "\n",
    "#冻结前面的5个卷积组，只训练自定义的全连接层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "print('[INFO] compiling model')\n",
    "sgd=SGD(lr=0.0001,momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=sgd)\n",
    "print('[INFO] training model')\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=40, validation_data=(x_valid,y_valid))\n",
    "print('[INFO] saving model and weights')\n",
    "#保存模型（不含权重）\n",
    "model_json=model.to_json()\n",
    "open('model_architecture.json','w').write(model_json)\n",
    "#保存权重\n",
    "model.save_weights('transfer_learning_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
