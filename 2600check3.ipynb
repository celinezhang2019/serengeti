{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 尝试2600张图片的快速建模，摸清serengeti图形数据简单建模的acc究竟为什么水平\n",
    "\n",
    "- 均为尺寸很大的彩色图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### including 3 datasets\n",
    "- train   70%\n",
    "- validate  20%\n",
    "- test   10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  Data prepare: 2 classes [5,21] for quick check \n",
    "# VGG data prepare\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_file = '/root/data/S10.json'\n",
    "with open(train_file) as data_file:\n",
    "    train_anns=json.load(data_file)\n",
    "\n",
    "\n",
    "img_5=[]\n",
    "for i in train_anns['annotations']:\n",
    "    if i['category_id'] == 5:\n",
    "        img_5.append(i['image_id']+'.JPG')\n",
    "img_5_1w = random.sample(img_5, 1500)\n",
    "\n",
    "img_21=[]\n",
    "for i in train_anns['annotations']:\n",
    "    if i['category_id'] == 21:\n",
    "        img_21.append(i['image_id']+'.JPG')\n",
    "img_21_1w = random.sample(img_21,1500)\n",
    "\n",
    "img_list = img_5_1w+img_21_1w\n",
    "\n",
    "label_dict = {}\n",
    "for i in train_anns['annotations']:\n",
    "    i_new = i['image_id'] + '.JPG'\n",
    "    if i_new in img_list:\n",
    "        label_dict[i_new]=i['category_id']\n",
    "        \n",
    "df = pd.DataFrame.from_dict(label_dict,orient='index',columns=['label'])\n",
    "df = df.reset_index().rename(columns={'index':'image_id'})\n",
    "print(df.head())\n",
    "\n",
    "df['label'].value_counts().plot.bar()\n",
    "plt.show()\n",
    "\n",
    "df.label.unique()\n",
    "\n",
    "df.loc[df.label == 39, 'label']=21\n",
    "\n",
    "df.label.unique()\n",
    "\n",
    "df['label'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了模仿简书上的VGG迁移学习的code做准备，变成0-1 二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.label == 5, 'label']=0\n",
    "df.loc[df.label == 21, 'label']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总共2600条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现有些图像虽然现在数据集中，但却实际并不存在于图像文件夹中\n",
    "\n",
    "查找实际不存在的images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = df['image_id'].tolist()\n",
    "path = '/root/data/'\n",
    "\n",
    "count = 0\n",
    "nonelist = []\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path)\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist.append(img_name)\n",
    "\n",
    "len(nonelist)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面来看，发现18个不存在的图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看是哪些图:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去除这些不存在的图形:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[~df.image_id.isin(nonelist)]\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上可见，数据集还剩下2582条观测值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分数据集：  \n",
    "\n",
    "70% vs 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate0_df = train_test_split(df1, test_size=0.30, random_state=523)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate0_df = validate0_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df, test_df = train_test_split(validate0_df, test_size=0.30, random_state=912)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = train_df['image_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.empty((len(imglist),227,227,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.empty((len(imglist),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2065, 227, 227, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2065, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2065, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/root/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将训练集的像素点转换成像素值：\n",
    "\n",
    "先不做255标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "nonelist=[]\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(227,227))\n",
    "        X_train[count]=img\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist.append(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再看看有没有不存在的图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nonelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看数据集转化好了么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备Y_train数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_df['label']\n",
    "Y_train = [i for i in label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_train是list格式的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看X_train是什么格式：\n",
    "\n",
    "发现是numpy.ndarray格式的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将Y_train的类型转变成numpy.ndarray格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=d.reshape(len(Y_train),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 到此，train_df已经变成了X_train, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 接下来，准备validate_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = validate_df['image_id'].tolist()\n",
    "X_validate = np.empty((len(imglist),227,227,3))\n",
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(517, 227, 227, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "nonelist_validate=[]\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(227,227))\n",
    "        X_validate[count]=img\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist_validate.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(517, 227, 227, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = validate_df['label']\n",
    "Y_validate = [i for i in label]\n",
    "Y_validate = np.array(Y_validate)\n",
    "Y_validate = Y_validate.reshape(len(Y_validate),1)\n",
    "Y_validate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(517, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validate[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "！！需要将5=斑马,21=母狮子 重新赋值成0和1，这样的话，下面的哑变量的取值就只会从0-1取2个值，而不会有21个哑变量了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train[Y_train==5] = 0\n",
    "# Y_train[Y_train==21] = 1\n",
    "\n",
    "# Y_validate[Y_validate==5] = 0\n",
    "# Y_validate[Y_validate==21] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备test_df："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = test_df['image_id'].tolist()\n",
    "X_test = np.empty((len(imglist),227,227,3))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "nonelist_test=[]\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(227,227))\n",
    "        X_test[count]=img\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist_test.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = test_df['label']\n",
    "Y_test = [i for i in label]\n",
    "Y_test = np.array(Y_test)\n",
    "Y_test = Y_test.reshape(len(Y_test),1)\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证，看看里面值对的上么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classes_num = 2\n",
    "batch_size = 64\n",
    "epochs_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten,Dense,Dropout,Input\n",
    "from keras.applications import VGG16\n",
    "from load_data import load_data_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model \n",
    "from keras.utils import np_utils\n",
    "import config\n",
    "print('[INFO] loading dataset......')\n",
    "(x_train,y_train)=(X_train, Y_train)\n",
    "(x_valid,y_valid)=(X_validate, Y_validate)\n",
    "\n",
    "y_train=np_utils.to_categorical(y_train,2)\n",
    "y_valid=np_utils.to_categorical(y_valid,2)\n",
    "print('[INFO] initializing model......')\n",
    "base_model=VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(227,227,3)))\n",
    "\n",
    "#微调\n",
    "head_model=base_model.output\n",
    "head_model=Flatten(name=\"flatten\")(head_model)\n",
    "head_model = Dense(512, activation=\"relu\")(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model=Dense(64,activation='relu')(head_model)\n",
    "head_model = Dense(len(config.CLASSES), activation=\"softmax\")(head_model)\n",
    "model=Model(base_model.input,head_model)\n",
    "\n",
    "#冻结前面的5个卷积组，只训练自定义的全连接层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "print('[INFO] compiling model')\n",
    "sgd=SGD(lr=0.0001,momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=sgd)\n",
    "print('[INFO] training model')\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=2, validation_data=(x_valid,y_valid))\n",
    "print('[INFO] saving model and weights')\n",
    "#保存模型（不含权重）\n",
    "model_json=model.to_json()\n",
    "open('model_architecture.json','w').write(model_json)\n",
    "#保存权重\n",
    "model.save_weights('transfer_learning_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
