{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 尝试2600张图片的快速建模，摸清serengeti图形数据简单建模的acc究竟为什么水平\n",
    "\n",
    "- 均为尺寸很大的彩色图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Data prepare: 2 classes [5,21] for quick check \n",
    "# VGG data prepare\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_file = '/root/data/S10.json'\n",
    "with open(train_file) as data_file:\n",
    "    train_anns=json.load(data_file)\n",
    "\n",
    "\n",
    "img_5=[]\n",
    "for i in train_anns['annotations']:\n",
    "    if i['category_id'] == 5:\n",
    "        img_5.append(i['image_id']+'.JPG')\n",
    "img_5_1w = random.sample(img_5, 1300)\n",
    "\n",
    "img_21=[]\n",
    "for i in train_anns['annotations']:\n",
    "    if i['category_id'] == 21:\n",
    "        img_21.append(i['image_id']+'.JPG')\n",
    "img_21_1w = random.sample(img_21,1300)\n",
    "\n",
    "img_list = img_5_1w+img_21_1w\n",
    "\n",
    "label_dict = {}\n",
    "for i in train_anns['annotations']:\n",
    "    i_new = i['image_id'] + '.JPG'\n",
    "    if i_new in img_list:\n",
    "        label_dict[i_new]=i['category_id']\n",
    "        \n",
    "df = pd.DataFrame.from_dict(label_dict,orient='index',columns=['label'])\n",
    "df = df.reset_index().rename(columns={'index':'image_id'})\n",
    "print(df.head())\n",
    "\n",
    "df['label'].value_counts().plot.bar()\n",
    "plt.show()\n",
    "\n",
    "df.label.unique()\n",
    "\n",
    "df.loc[df.label == 39, 'label']=21\n",
    "\n",
    "df.label.unique()\n",
    "\n",
    "df['label'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了模仿简书上的VGG迁移学习的code做准备，变成0-1 二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.label == 5, 'label']=0\n",
    "df.loc[df.label == 21, 'label']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总共2600条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现有些图像虽然现在数据集中，但却实际并不存在于图像文件夹中\n",
    "\n",
    "查找实际不存在的images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = df['image_id'].tolist()\n",
    "path = '/root/data/'\n",
    "\n",
    "count = 0\n",
    "nonelist = []\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path)\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist.append(img_name)\n",
    "\n",
    "len(nonelist)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面来看，发现18个不存在的图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看是哪些图:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去除这些不存在的图形:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[~df.image_id.isin(nonelist)]\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上可见，数据集还剩下2582条观测值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分数据集：  \n",
    "\n",
    "80% vs 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df1, test_size=0.20, random_state=523)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = train_df['image_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.empty((len(imglist),227,227,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.empty((len(imglist),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2065, 227, 227, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2065, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2065, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/root/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将训练集的像素点转换成像素值：\n",
    "\n",
    "先不做255标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "nonelist=[]\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(227,227))\n",
    "        X_train[count]=img\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist.append(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再看看有没有不存在的图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nonelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看数据集转化好了么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备Y_train数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_df['label']\n",
    "Y_train = [i for i in label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_train是list格式的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看X_train是什么格式：\n",
    "\n",
    "发现是numpy.ndarray格式的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将Y_train的类型转变成numpy.ndarray格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=d.reshape(2065,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 到此，train_df已经变成了X_train, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 接下来，准备validate_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = validate_df['image_id'].tolist()\n",
    "X_validate = np.empty((len(imglist),227,227,3))\n",
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(517, 227, 227, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "nonelist_validate=[]\n",
    "for img_name in imglist:\n",
    "    img_path = path + img_name\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(227,227))\n",
    "        X_validate[count]=img\n",
    "        count+=1\n",
    "    except:\n",
    "        nonelist_validate.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(517, 227, 227, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = validate_df['label']\n",
    "Y_validate = [i for i in label]\n",
    "Y_validate = np.array(Y_validate)\n",
    "Y_validate = Y_validate.reshape(len(Y_validate),1)\n",
    "Y_validate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(517, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validate[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "！！需要将5=斑马,21=母狮子 重新赋值成0和1，这样的话，下面的哑变量的取值就只会从0-1取2个值，而不会有21个哑变量了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[Y_train==5] = 0\n",
    "Y_train[Y_train==21] = 1\n",
    "\n",
    "Y_validate[Y_validate==5] = 0\n",
    "Y_validate[Y_validate==21] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classes_num = 2\n",
    "batch_size = 32\n",
    "epochs_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -- coding: utf-8 --\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "# from keras.layers import Conv2D, MaxPooling2D\n",
    "# import keras\n",
    "# from keras.datasets import cifar10\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "# import matplotlib.pyplot as plt\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.applications import VGG16\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# classes_num = 2\n",
    "# batch_size = 32\n",
    "# epochs_num = 100\n",
    "\n",
    "# def quality_classify_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Flatten(input_shape=(4,4,512)))# 4*4*512\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(classes_num, activation='softmax'))  # 多分类\n",
    "\n",
    "#     opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# def train():\n",
    "#     # 数据载入\n",
    "#     x_train = X_train\n",
    "#     y_train = Y_train\n",
    "#     x_test = X_test\n",
    "#     y_test = Y_test\n",
    "\n",
    "#     # 多分类标签生成\n",
    "#     y_train = keras.utils.to_categorical(y_train, classes_num)\n",
    "#     y_test = keras.utils.to_categorical(y_test, classes_num)\n",
    "#     # 生成训练数据\n",
    "#     x_train = x_train.astype('float32')\n",
    "#     x_test = x_test.astype('float32')\n",
    "\n",
    "#     datagan = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#     # 加载预训练好的卷积基\n",
    "#     conv_base = VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "#     # 用预训练好的卷积基处理训练集提取特征\n",
    "#     sample_count = len(y_train)\n",
    "#     train_features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "#     train_labels = np.zeros(shape=(sample_count, classes_num))\n",
    "#     train_generator = datagan.flow(x_train, y_train, batch_size=batch_size)\n",
    "#     i = 0\n",
    "#     for inputs_batch, labels_batch in train_generator:\n",
    "#         features_batch = conv_base.predict(inputs_batch)\n",
    "#         train_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "#         train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "#         i += 1\n",
    "#         if i * batch_size >= sample_count:\n",
    "#             break\n",
    "#     # train_features = np.reshape(train_features, (sample_count, 4*4*512))\n",
    "\n",
    "#     # 用预训练好的卷积基处理验证集提取特征\n",
    "#     sample_count = len(y_test)\n",
    "#     test_generator = datagan.flow(x_test, y_test, batch_size=batch_size)\n",
    "#     test_features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "#     test_labels = np.zeros(shape=(sample_count, classes_num))\n",
    "#     i = 0\n",
    "#     for inputs_batch, labels_batch in test_generator:\n",
    "#         features_batch = conv_base.predict(inputs_batch)\n",
    "#         test_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "#         test_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "#         i += 1\n",
    "#         if i * batch_size >= sample_count:\n",
    "#             break\n",
    "#     # test_features = np.reshape(test_features, (sample_count, 4*4*512))\n",
    "\n",
    "#     model = quality_classify_model()\n",
    "\n",
    "#     # hist = model.fit_generator(train_datagan.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch = 8000, epochs = epochs_num, validation_data=(x_test,y_test), shuffle=True)\n",
    "#     hist = model.fit(train_features, train_labels, batch_size=batch_size, epochs=epochs_num, validation_data=(test_features, test_labels))\n",
    "\n",
    "#     model.save('./extract_features/cifar10_model.hdf5') \n",
    "#     model.save_weights('./extract_features/cifar10_model_weight.hdf5')\n",
    "\n",
    "#     hist_dict = hist.history\n",
    "#     print(\"train acc:\")\n",
    "#     print(hist_dict['acc'])\n",
    "#     print(\"validation acc:\")\n",
    "#     print(hist_dict['val_acc'])\n",
    "\n",
    "#     train_acc = hist.history['acc']\n",
    "#     val_acc = hist.history['val_acc']\n",
    "#     train_loss = hist.history['loss']\n",
    "#     val_loss = hist.history['val_loss']\n",
    "\n",
    "#     # 绘图\n",
    "#     epochs = range(1, len(train_acc)+1)\n",
    "#     plt.plot(epochs, train_acc, 'bo', label = 'Training acc')\n",
    "#     plt.plot(epochs, val_acc, 'r', label = 'Validation acc')\n",
    "#     plt.title('Training and validation accuracy')\n",
    "#     plt.legend()\n",
    "#     plt.savefig(\"accuracy.png\")\n",
    "#     plt.figure() # 新建一个图\n",
    "#     plt.plot(epochs, train_loss, 'bo', label = 'Training loss')\n",
    "#     plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "#     plt.title('Training and validation loss')\n",
    "#     plt.legend()\n",
    "#     plt.savefig(\"loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面来自简书的model code 会报错\n",
    "\n",
    "重新查找vgg 迁移学习的code进行尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten,Dense,Dropout,Input\n",
    "from keras.applications import VGG16\n",
    "from load_data import load_data_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model \n",
    "from keras.utils import np_utils\n",
    "import config\n",
    "print('[INFO] loading dataset......')\n",
    "(x_train,y_train)=(X_train, Y_train)\n",
    "(x_valid,y_valid)=(X_validate, Y_validate)\n",
    "\n",
    "y_train=np_utils.to_categorical(y_train,2)\n",
    "y_valid=np_utils.to_categorical(y_valid,2)\n",
    "print('[INFO] initializing model......')\n",
    "base_model=VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(227,227,3)))\n",
    "\n",
    "#微调\n",
    "head_model=base_model.output\n",
    "head_model=Flatten(name=\"flatten\")(head_model)\n",
    "head_model = Dense(512, activation=\"relu\")(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model=Dense(64,activation='relu')(head_model)\n",
    "head_model = Dense(len(config.CLASSES), activation=\"softmax\")(head_model)\n",
    "model=Model(base_model.input,head_model)\n",
    "\n",
    "#冻结前面的5个卷积组，只训练自定义的全连接层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "print('[INFO] compiling model')\n",
    "sgd=SGD(lr=0.0001,momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=sgd)\n",
    "print('[INFO] training model')\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=2, validation_data=(x_valid,y_valid))\n",
    "print('[INFO] saving model and weights')\n",
    "#保存模型（不含权重）\n",
    "model_json=model.to_json()\n",
    "open('model_architecture.json','w').write(model_json)\n",
    "#保存权重\n",
    "model.save_weights('transfer_learning_weights.h5', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
